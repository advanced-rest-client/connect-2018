<link rel="import" href="../../bower_components/polymer/polymer-element.html">
<link rel="import" href="../../bower_components/polymer/lib/elements/dom-if.html">
<link rel="import" href="../../bower_components/polymer/lib/utils/render-status.html">
<link rel="import" href="../../bower_components/anypoint-styles/typography.html">
<link rel="import" href="../../bower_components/anypoint-styles/colors.html">
<link rel="import" href="../../bower_components/iron-icon/iron-icon.html">
<link rel="import" href="../../bower_components/paper-icon-button/paper-icon-button.html">
<link rel="import" href="../../bower_components/paper-input/paper-input.html">
<link rel="import" href="../botcons.html">
<dom-module id="user-input">
  <template>
    <style>
    :host {
      display: block;
      @apply --anypoint-font-body;
    }

    .user-input-container {
      background-color: var(--anypoint-color-aluminum1);
      padding: 16px;
      border-radius: 6px;
      @apply --layout-horizontal;
      @apply --layout-center;
      @apply --flex;
    }

    .speach-indicator {
      margin-right: 12px;
      position: relative;
      width: 40px;
      height: 40px;
      cursor: pointer;
      user-select: none;
      @apply --layout-horizontal;
      @apply --layout-center-center;
    }

    .text-field {
      @apply --layout-horizontal;
      @apply --layout-center;
      @apply --layout-flex;
    }

    paper-input {
      @apply --layout-flex;
    }

    .bubble {
      background-color: var(--anypoint-color-red3);
      width: 40px;
      height: 40px;
      position: absolute;
      border-radius: 50%;
      display: none;
    }

    :host([listening]) .bubble {
      -webkit-animation: mic-bounce 1.4s infinite ease-in-out both;
      animation: mic-bounce 1.4s infinite ease-in-out both;
      display: block;
    }

    :host([listening]) .speach-indicator {
      color: #fff;
    }

    @keyframes mic-bounce {
      0%, 80%, 100% {
        -webkit-transform: scale(0.5);
        transform: scale(0.5);
      } 40% {
        -webkit-transform: scale(1.0);
        transform: scale(1.0);
      }
    }
    </style>
    <div class="user-input-container">
      <template is="dom-if" if="[[renderMic]]">
        <div class="speach-indicator" on-click="_micTapHandler">
          <span class="bubble"></span>
          <iron-icon icon="botcons:mic"></iron-icon>
        </div>
      </template>
      <div class="text-field">
        <paper-input id="input" label="Say something..." no-label-float on-keydown="_inputKeydownHandler" value="{{value}}"></paper-input>
        <paper-icon-button icon="botcons:send" on-click="_sendHandler"></paper-icon-button>
      </div>
    </div>
  </template>
  <script>
    /**
     * @customElement
     * @polymer
     */
    class UserInput extends Polymer.Element {
      static get is() { return 'user-input'; }
      static get properties() {
        return {
          /**
           * User entered or recognized value
           */
          value: {
            type: String,
            notify: true
          },
          /**
           * Flag that determines if speach recognition API is available.
           */
          hasSpeachRecognition: {
            type: Boolean,
            readOnly: true,
            value: function() {
              return 'webkitSpeechRecognition' in window;
            }
          },
          /**
           * Microphone permissions are already granted to the user.
           * Can use microphone API.
           */
          micGranted: Boolean,
          /**
           * Never asked for microphone permissions.
           */
          micPrompt: Boolean,
          /**
           * Microphone permissions has ben denied by the user
           * or the API (Permissions or SpeechRecognition) is not supported
           * by current browser.
           */
          micDenied: Boolean,
          /**
           * Computed value, true if the microphone icon can be rendered,
           */
          renderMic: {
            type: Boolean,
            readOnly: true,
            computed: '_computeRenderMic(hasSpeachRecognition, micGranted, micPrompt, micDenied)'
          },
          /**
           * True if the element is currently rendered by the parent element.
           */
          opened: Boolean,
          /**
           * True if the microphone is currently active
           */
          listening: {
            type: Boolean,
            reflectToAttribute: true,
            computed: '_computeListening(opened, micGranted, micEnabled)',
            observer: '_listeningChanged'
          },
          /**
           * True when microphone is in use.
           */
          micEnabled: Boolean,
          _firstCharRe: {
            type: Object,
            readOnly: true,
            value: function() {
              return /\S/;
            }
          }
        };
      }

      constructor() {
        super();
        this._permissionStatusChanged = this._permissionStatusChanged.bind(this);
        this._speachResultHandler = this._speachResultHandler.bind(this);
        this._speachErrorHandler = this._speachErrorHandler.bind(this);
        this._speachEndHandler = this._speachEndHandler.bind(this);
        this._transcriptTimerHandler = this._transcriptTimerHandler.bind(this);
      }

      connectedCallback() {
        super.connectedCallback();
        if (!this._permissionQuery) {
          this.checkPermissions();
        }
      }
      /**
       * Checks for `microphone` permissions state.
       */
      checkPermissions() {
        if (!navigator.permissions || !navigator.permissions.query || !this.hasSpeachRecognition) {
          this._permissionQuery = Promise.resolve({
            state: 'denied'
          });
          return;
        }
        this._permissionQuery = navigator.permissions.query({name:'microphone'})
        .then((result) => {
          this._setPermissions(result.state);
          result.onchange = this._permissionStatusChanged;
        });
      }
      /**
       * Handler for permission change state events.
       *
       * @param {Event} e
       */
      _permissionStatusChanged(e) {
        const state = e.target.state;
        this._setPermissions(state);
      }
      /**
       * Sets permissions state depending on current `state` value.
       *
       * @param {String} state Permissions API state.
       */
      _setPermissions(state) {
        if (state === 'granted') {
          this.micGranted = true;
          if (this.micPrompt) {
            this.micPrompt = false;
          }
          if (this.micPrompt) {
            this.micDenied = false;
          }
        } else if (state === 'prompt') {
          this.micPrompt = true;
          if (this.micGranted) {
            this.micGranted = false;
          }
          if (this.micPrompt) {
            this.micDenied = false;
          }
        } else {
          this.micDenied = true;
          if (this.micGranted) {
            this.micGranted = false;
          }
          if (this.micPrompt) {
            this.micDenied = false;
          }
        }
      }
      /**
       * Computes value for `renderMic` property.
       *
       * @param {Boolean} micGranted
       * @param {Boolean} micPrompt
       * @return {Boolean}
       */
      _computeRenderMic(hasSpeachRecognition, micGranted, micPrompt) {
        return !!(hasSpeachRecognition && (micPrompt || micGranted));
      }

      _computeListening(opened, micGranted, micEnabled) {
        return !!(opened && micGranted && micEnabled);
      }
      /**
       * Starts the microphone listener when the `state` is true.
       * @param {Boolean} state
       */
      _listeningChanged(state) {
        if (state) {
          this.startListening();
        }
      }
      /**
       * Listens to the user voice input.
       */
      startListening() {
        /* global webkitSpeechRecognition */
        if (this.__recognition) {
          this._speachEndHandler();
        }
        const recognition = new webkitSpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        recognition.addEventListener('result', this._speachResultHandler);
        recognition.addEventListener('error', this._speachErrorHandler);
        recognition.addEventListener('end', this._speachEndHandler);
        recognition.start();
        this.__recognition = recognition;
        this.listening = true;
      }
      /**
       * Handler for speach recognition result event.
       * Updates the state od the app depending on the result.
       * @param {Event} e Speach event.
       */
      _speachResultHandler(e) {
        this._cancelTimer();
        let interim = '';
        let transcript = '';
        for (let i = e.resultIndex, len = e.results.length; i < len; ++i) {
          if (e.results[i].isFinal) {
            transcript += e.results[i][0].transcript;
          } else {
            interim += e.results[i][0].transcript;
          }
        }
        transcript = this.capitalize(transcript);
        interim = this.capitalize(interim);
        if (transcript && !interim) {
          this._updateTranscript(transcript);
        } else if (interim) {
          this._updateInterim(interim);
        }
      }
      /**
       * Handler for speach error event.
       * @param {Event} e
       */
      _speachErrorHandler(e) {
        this._cancelTimer();
        this.listening = false;
        console.log('Speach recognition error');
        switch (e.error) {
          case 'no-speech':
            console.log('No speach'); // Do nothing
            break;
          default:
            break;
        }
      }
      /**
       * Clears the recognition object when not used.
       */
      _speachEndHandler() {
        this._cancelTimer();
        const recognition = this.__recognition;
        recognition.removeEventListener('result', this._speachResultHandler);
        recognition.removeEventListener('error', this._speachErrorHandler);
        recognition.removeEventListener('end', this._speachEndHandler);
        this.__recognition = undefined;
        this.micEnabled = false;
        this.listening = false;
      }
      /**
       * Updates the sate of user voice query when there's no final request
       * od fpeach recognition. It removes the label and adds placeholder
       * ewith the interm value.
       *
       * @param {String} query Recognized user query
       */
      _updateInterim(query) {
        const input = this.$.input;
        if (input.label) {
          this.__originalLabel = input.label;
          input.label = '';
        }
        input.placeholder = query;
      }
      /**
       * This is called when final result of speach recognition is available.
       * It sets the transcript handler so if the user speak again in about
       * ~1000 ms it will not report the results back to the app but continue to
       * listen.
       *
       * @param {String} transcript Recognized final query.
       */
      _updateTranscript(transcript) {
        const input = this.$.input;
        input.placeholder = '';
        input.label = this.__originalLabel;
        this.value = transcript;
        this._transcriptTimer = setTimeout(this._transcriptTimerHandler, 1000);
      }
      /**
       * This is called by the transcript timeout.
       * Sends current query to the app
       */
      _transcriptTimerHandler() {
        this._transcriptTimer = undefined;
        this._sendHandler();
        this._transcriptTimer = undefined;
        this.__recognition.stop();
      }
      /**
       * Cancels the transcipt timer that sends user query to the app in delay.
       */
      _cancelTimer() {
        if (this._transcriptTimer === undefined) {
          return;
        }
        clearTimeout(this._transcriptTimer);
        this._transcriptTimer = undefined;
      }
      /**
       * Handler for the send button click
       */
      _sendHandler() {
        const value = this.value;
        if (!value) {
          return;
        }
        const e = new CustomEvent('user-input', {
          detail: {
            value: value
          }
        });
        this.dispatchEvent(e);
        Polymer.RenderStatus.afterNextRender(this, () => {
          this.value = '';
        });
      }
      /**
       * Handles "Enter" key and calls `_sendHandler()` if user Enter the input.
       *
       * @param {KeyboardEvent} e
       */
      _inputKeydownHandler(e) {
        if (e.key === 'Enter') {
          this._sendHandler();
        }
      }
      /**
       * Handler for the microphone click event.
       */
      _micTapHandler() {
        if (this.listening) {
          this.__recognition.stop();
        } else if (!this.micDenied) {
          this.value = '';
          if (this.micEnabled) {
            this.startListening();
          } else {
            this.micEnabled = true;
          }
        }
      }
      /**
       * Capitalizes the sentence.
       * @param {String} s A sentence to capitalize
       * @return {String} Capitalized sentence.
       */
      capitalize(s) {
        return s.replace(this._firstCharRe, function(m) { return m.toUpperCase(); });
      }
      /**
       * Dispatched when user finished input
       *
       * @event user-input
       * @param {String} value User input.
       */
    }
    window.customElements.define(UserInput.is, UserInput);
  </script>
</dom-module>
